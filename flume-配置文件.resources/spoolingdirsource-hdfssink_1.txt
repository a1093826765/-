#a1是agent的名称，在a1中定义一个r1，如果有多个，可用空格间隔
a1.sources = r1
a1.channels = c1
a1.sinks = k1

#组名.属性名=属性值
a1.sources.r1.type = spooldir
a1.sources.r1.command = /root/data/flume
a1.sources.r1.deserializer.outputCharset = UTF-8 

#定义channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

#定义sink
a2.sinks.k1.type = hdfs
#一旦路径中含有基于时间的转义序列，要求event的header中必须有timestamp=时间戳，如果没有需要启动使用本地时间戳
a2.sinks.k1.hdfs.path = hdfs://localhost1:9000/flume/%Y%m%d/%H/%M
#上传文件的前缀
a2.sinks.k1.hdfs.filePrefix = hiveLogs-

##以下三个和目录滚动相关,目录一旦设置了时间转义序列，基于时间戳滚动
#是否按照时间滚动文件夹，四舍五入（这里只能舍，往下取值，基于下面两个参数取舍）
a2.sinks.k1.hdfs.round = true
#多少时间单位创建一个新的文件夹
a2.sinks.k1.hdfs.roundValue = 1
#重新定义时间单位
a2.sinks.k1.hdfs.roundUnit = minute

#是否使用本地时间戳
a2.sinks.k1.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a2.sinks.k1.hdfs.batchSize = 100

##以下三个和文件滚动相关（随意满足一个即滚动）
#多久生成一个新的文件
a2.sinks.k1.hdfs.rollInterval = 30 
#设置每个文件的滚动大小
a2.sinks.k1.hdfs.rollSize = 134217700
#每写多少个event滚动一起
a2.sinks.k1.hdfs.rollCount = 0
#以不压缩的文本形式保存数据
a1.sinks.k1.hdfs.fileType=DataStream

#连接组件，同一个sources可以连接多个channels,一个sink只能从一个channels拿数据
a1.sources.r1.channels = c1
a1.sinks.k1.channel=c1
